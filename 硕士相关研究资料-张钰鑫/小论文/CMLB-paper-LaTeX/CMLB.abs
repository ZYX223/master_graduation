In parallel applications, mapping parallel threads to cores according to the access behavior plays an important role to optimize the applications performance. When a parallel application runs on modern NUMA (non-uniform memory access) architecture, the efficiency of communication between threads and the memory bandwidth between NUMA nodes are not balanced, which indirectly increase the average latency and the execution time of the application. Previous works on thread mapping mostly focus on the locality of memory accesses to improve the communication efficiency. However, maximizing the locality may cause memory congestion because of the imbalance on memory bandwidth between nodes. In this paper, we propose a thread mapping method that works on improving the locality of communication as well as avoiding memory congestion problem. We have tested CMLB with rotor35-omp program and several applications from NAS parallel benchmark and Parsec benchmark. Experiments show that CMLB could greatly balance the memory bandwidth between nodes to reduce the memory latency and also improve the locality of communication, get the better performance than the state-of-the-art mapping methods.
